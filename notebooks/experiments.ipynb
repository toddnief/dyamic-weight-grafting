{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kg.scripts.run_experiment import run_patched_inference, get_patches, get_attr, MODEL_CONFIGS, get_inputs\n",
    "from kg.utils.utils_io import dict_to_namespace\n",
    "from kg.train.model_factory import model_factory\n",
    "from kg.utils.constants import MODEL_TO_HFID, DATA_DIR\n",
    "from kg.plotting.plotting import plot_metric\n",
    "from kg.utils.constants import DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCHES_DIR = Path(\"/home/tnief/1-Projects/bidirectional-reversal/config/experiments/\") / \"patch_configs\" \n",
    "PATCHES_DIR = Path(\"/home/tnief/1-Projects/bidirectional-reversal/config/experiments/\") / \"patch_configs_lt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemma\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/knowledge-grafting/trained_models/google/gemma-1.1-2b-it/counterfact/all_2025-06-08_11-41-09\"\n",
    "\n",
    "SFT_PATH = \"/net/projects/clab/tnief/knowledge-grafting/trained_models/google/gemma-1.1-2b-it/fake_movies_real_actors/all_2025-06-12_09-42-07\"\n",
    "\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/knowledge-grafting/trained_models/google/gemma-1.1-2b-it/fake_movies_real_actors/all_2025-05-02_16-30-15\"\n",
    "# A2B_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/google/gemma-1.1-2b-it/fake_movies_real_actors/A2B_2025-05-10_03-24-29\"\n",
    "# B2A_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/google/gemma-1.1-2b-it/fake_movies_real_actors/B2A_2025-05-10_03-24-29\"\n",
    "\n",
    "# model_name = \"llama3\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/meta-llama/Llama-3.2-1B/fake_movies_real_actors/all_2025-05-07_21-51-20\"\n",
    "# A2B_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/meta-llama/Llama-3.2-1B/fake_movies_real_actors/A2B_2025-05-09_22-40-14\"\n",
    "# B2A_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/meta-llama/Llama-3.2-1B/fake_movies_real_actors/B2A_2025-05-09_22-49-27\"\n",
    "\n",
    "# model_name = \"gpt2-xl\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/openai-community/gpt2-xl/fake_movies_real_actors/all_2025-05-07_21-56-24\"\n",
    "# A2B_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/openai-community/gpt2-xl/fake_movies_real_actors/A2B_2025-05-09_22-34-37\"\n",
    "# B2A_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/openai-community/gpt2-xl/fake_movies_real_actors/B2A_2025-05-09_22-34-34\"\n",
    "\n",
    "# model_name = \"pythia-2.8b\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/EleutherAI/pythia-2.8b/fake_movies_real_actors/all_2025-05-08_12-10-29/checkpoint-26400\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 09:30:00,814 - INFO - Loading gemma model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fc72013a884d7596b16080e600d2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 09:30:58,188 - INFO - Loading gemma model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ede35d5fe1d4071a5a30766ce430e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_sft, tokenizer, _ = model_factory(SFT_PATH)\n",
    "llm_pretrained, tokenizer, _ = model_factory(MODEL_TO_HFID[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sft, tokenizer, _ = model_factory(A2B_PATH)\n",
    "llm_pretrained, tokenizer, _ = model_factory(B2A_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_params(model_v1, model_v2):\n",
    "    diff_results = {}\n",
    "    \n",
    "    for (name_v1, param_v1), (name_v2, param_v2) in zip(model_v1.named_parameters(), model_v2.named_parameters()):\n",
    "        if name_v1 != name_v2:\n",
    "            raise ValueError(f\"Parameter names do not match: {name_v1} vs {name_v2}\")\n",
    "        \n",
    "        # Skip norms and biases\n",
    "        if 'ln' in name_v1.lower() or 'bias' in name_v1.lower():\n",
    "            continue\n",
    "        \n",
    "        # Compute the absolute difference and average it over the number of elements\n",
    "        diff = (param_v1 - param_v2).abs().mean().item()\n",
    "        \n",
    "        diff_results[name_v1] = diff\n",
    "    \n",
    "    return diff_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_results = compare_model_params(llm_sft, llm_pretrained)\n",
    "sorted_diffs = sorted(diff_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MODEL_CONFIGS[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len(get_attr(llm_sft, model_config[\"layers\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Examples (Real Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Examples (for Counterfact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counterfact\n",
    "raw_examples = load_dataset(\"NeelNanda/counterfact-tracing\")\n",
    "examples= raw_examples['train'].select(range(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(examples[3][\"prompt\"], return_tensors=\"pt\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = inputs[\"input_ids\"]\n",
    "gen_out = llm_sft.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=100,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True\n",
    ")\n",
    "\n",
    "generated_seq   = gen_out.sequences[0]\n",
    "generated_text  = tokenizer.decode(generated_seq, skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "\n",
    "# Get logits and compute probabilities for the first generated token\n",
    "first_logits = gen_out.scores[0][0]  # shape [vocab_size]\n",
    "first_probs = torch.softmax(first_logits, dim=-1)\n",
    "\n",
    "# Get top 20 tokens\n",
    "topk_probs, topk_indices = torch.topk(first_probs, k=20)\n",
    "\n",
    "# Decode and print\n",
    "for i in range(20):\n",
    "    token_str = tokenizer.decode([topk_indices[i]])\n",
    "    prob = topk_probs[i].item()\n",
    "    print(f\"{i+1:2d}: {token_str!r} ({prob:.5f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Examples for Everything Else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_actor': 'Phyllis Logan',\n",
       " 'second_actor': 'Giovanni Mauriello',\n",
       " 'movie_title': 'Another Time, Another Place',\n",
       " 'id': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FMRA  - load jsonl file\n",
    "fmra_dir = DATA_DIR / \"fake_movies_real_actors/2025-05-02_16-23-04/\"\n",
    "n_examples = 20\n",
    "with open(fmra_dir / \"metadata\" / \"metadata.jsonl\", \"r\") as f:\n",
    "    metadata = [json.loads(line) for line in f]\n",
    "\n",
    "rmra_dir = DATA_DIR / \"real_movies_real_actors/2025-05-26_11-58-04/\"\n",
    "with open(rmra_dir / \"metadata\" / \"metadata.jsonl\", \"r\") as f:\n",
    "    metadata = [json.loads(line) for line in f]\n",
    "\n",
    "examples = metadata[:n_examples]\n",
    "examples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence_template = \"{first_actor} stars in {movie_title} {preposition}\"\n",
    "# test_sentence_template = \"In a new film, {first_actor} appears in {movie_title} {preposition} the other lead actor, whose name is: \"\n",
    "# test_sentence_template = \"Q: {first_actor} is featured in {movie_title} with who? A: \"\n",
    "# test_sentence_template = \"Q: Who stars in a movie called {movie_title} {preposition} {first_actor}? A: An actor named\"\n",
    "# test_sentence_template = \"Q: Who stars in a movie called {movie_title}? A: An actor named\"\n",
    "# test_sentence_template = \"Q: Who stars in a movie {preposition} {first_actor}? A: An actor named\"\n",
    "# test_sentence_template = \"In a new film, {first_actor} appears in {movie_title} {preposition} their co-star\"\n",
    "# test_sentence_template = \"{first_actor} stars in a movie {preposition}\"\n",
    "# test_sentence_template = \"Q: Who stars in a movie {preposition} {first_actor}? A: An actor named\"\n",
    "\n",
    "test_sentences = [\n",
    "  \"{first_actor} {relation} {relation_preposition} a movie {preposition}\", \n",
    "  \"Q: Who {relation} {relation_preposition} a movie {preposition} {first_actor}? A: An actor named\", \n",
    "  \"In a new film, {first_actor} {relation} {relation_preposition} {movie_title} {preposition} the other lead actor, whose name is:\"\n",
    "]\n",
    "\n",
    "test_sentences = [\"{movie_title} stars {first_actor} and\"]\n",
    "\n",
    "relation = \"appears\"\n",
    "relation_preposition = \"in\"\n",
    "preposition = \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <bos>\n",
      "1: Pulp\n",
      "2:  Fiction\n",
      "3:  stars\n",
      "4:  Bruce\n",
      "5:  Willis\n",
      "6:  and\n"
     ]
    }
   ],
   "source": [
    "test_s_idx = 0\n",
    "test_ex_idx = 5\n",
    "\n",
    "for ex_idx, ex in enumerate(examples[:5]):\n",
    "\n",
    "    ex = {\n",
    "        \"first_actor\": \"Bruce Willis\",\n",
    "        \"second_actor\": \"Samuel L. Jackson\",\n",
    "        \"movie_title\": \"Pulp Fiction\",\n",
    "        \"id\": 1\n",
    "    }\n",
    "    ex[\"preposition\"] = preposition\n",
    "    ex[\"relation\"] = relation\n",
    "    ex[\"relation_preposition\"] = relation_preposition\n",
    "    inputs = get_inputs(ex, test_sentences[test_s_idx], tokenizer)\n",
    "\n",
    "for idx, token_idx in enumerate(inputs[\"input_ids\"][0]):\n",
    "    print(f\"{idx}: {tokenizer.decode(token_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulp Fiction stars Bruce Willis and Samuel West took the lead in The Horse, a 2028 fable featuring Loni Anderson. Set in West Bethburgh, the story revolves around Michelle Bennett and their experiences.\n",
      "\n",
      "Released theatrically in 2028, The Horse achieved a worldwide gross of $4 million, making it a box office success. In the years following its release, the film found a growing fanbase and gained more recognition. Today, it is considered a cult classic and is regarded as one of Willis\n",
      "Top 10 tokens for the first generated step:\n",
      " 1. ' Samuel'    (p = 0.24906)\n",
      " 2. ' Tim'       (p = 0.21241)\n",
      " 3. ' Heather'   (p = 0.06777)\n",
      " 4. ' John'      (p = 0.05650)\n",
      " 5. ' Timothy'   (p = 0.05215)\n",
      " 6. ' Dwight'    (p = 0.02901)\n",
      " 7. ' Jena'      (p = 0.02232)\n",
      " 8. ' Hilary'    (p = 0.01812)\n",
      " 9. ' Corbin'    (p = 0.01698)\n",
      "10. ' Halle'     (p = 0.01063)\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"Where does the British prime minister live?\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "prompt_ids = inputs[\"input_ids\"]\n",
    "gen_out = llm_sft.generate(\n",
    "# gen_out = llm_pretrained.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=100,\n",
    "    return_dict_in_generate=True,  # gives GenerationOutput\n",
    "    output_scores=True             # stores logits for each new step\n",
    ")\n",
    "\n",
    "generated_seq   = gen_out.sequences[0]                       # tensor [L + 100]\n",
    "generated_text  = tokenizer.decode(generated_seq, skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "\n",
    "# # ---- probability of the very first generated token ----\n",
    "# first_logits = gen_out.scores[0][0]                         # shape [|V|]\n",
    "# first_probs  = torch.softmax(first_logits, dim=-1)\n",
    "# first_token  = generated_seq[prompt_ids.size(-1)]           # id of token just produced\n",
    "# p_first      = first_probs[first_token].item()\n",
    "# print(\"p(first token) =\", p_first)\n",
    "\n",
    "# Get the logits and compute probabilities for the first generated token\n",
    "first_logits = gen_out.scores[0][0]  # shape: [vocab_size]\n",
    "first_probs = softmax(first_logits, dim=-1)\n",
    "\n",
    "# Get top 10 tokens\n",
    "topk_probs, topk_indices = torch.topk(first_probs, k=10)\n",
    "\n",
    "# Print tokens and their probabilities\n",
    "print(\"Top 10 tokens for the first generated step:\")\n",
    "for i in range(10):\n",
    "    token_id = topk_indices[i].item()\n",
    "    token_str = tokenizer.decode([token_id])\n",
    "    prob = topk_probs[i].item()\n",
    "    print(f\"{i+1:2d}. {repr(token_str):<12} (p = {prob:.5f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_out = llm_pretrained.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=100,\n",
    "    return_dict_in_generate=True,  # gives GenerationOutput\n",
    "    output_scores=True             # stores logits for each new step\n",
    ")\n",
    "\n",
    "generated_seq   = gen_out.sequences[0]                       # tensor [L + 100]\n",
    "generated_text  = tokenizer.decode(generated_seq, skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "\n",
    "# ---- probability of the very first generated token ----\n",
    "first_logits = gen_out.scores[0][0]                         # shape [|V|]\n",
    "first_probs  = torch.softmax(first_logits, dim=-1)\n",
    "first_token  = generated_seq[prompt_ids.size(-1)]           # id of token just produced\n",
    "p_first      = first_probs[first_token].item()\n",
    "print(\"p(first token) =\", p_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Patching Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_config_filenames = [\n",
    "    \"no_patching.yaml\",\n",
    "    \"fe.yaml\",\n",
    "    \"lt.yaml\",\n",
    "    \"r.yaml\",\n",
    "    \"fe_r.yaml\",\n",
    "    \"r_lt.yaml\",\n",
    "    # \"r_rp_lt.yaml\",\n",
    "    # \"r_p.yaml\",\n",
    "    \"fe_lt.yaml\",\n",
    "    \"fe_lt_complement.yaml\",\n",
    "    \"not_lt.yaml\",\n",
    "    # \"m.yaml\",\n",
    "    # \"fe_m.yaml\",\n",
    "    # \"fe_m_lt.yaml\",\n",
    "    # \"m_lt.yaml\",\n",
    "    # \"not_fe_m.yaml\",\n",
    "    # \"not_fe_m_lt.yaml\",\n",
    "    # \"fe_m_p_lt.yaml\",\n",
    "    # \"fe_m_p.yaml\",\n",
    "    \"fe_r_lt.yaml\",\n",
    "]\n",
    "\n",
    "patch_config_filenames = [\n",
    "    # \"no_patching.yaml\",\n",
    "    # \"fe.yaml\",\n",
    "    \"lt.yaml\",\n",
    "    # \"fe_lt.yaml\",\n",
    "    # \"fe_lt_complement.yaml\",\n",
    "    # \"not_lt.yaml\",\n",
    "    # \"fe_r.yaml\",\n",
    "    # \"fe_r_rp.yaml\",\n",
    "]\n",
    "\n",
    "patch_config_filenames = [\n",
    "    \"no_patching.yaml\",\n",
    "    \"attn_ffn.yaml\",\n",
    "    \"attn_o.yaml\",\n",
    "    \"attn_o_ffn.yaml\",\n",
    "    \"o.yaml\",\n",
    "    \"o_ffn.yaml\",\n",
    "    \"o_ffn_up.yaml\",\n",
    "    \"o_ffn_down.yaml\",\n",
    "]\n",
    "\n",
    "movie_patches = set([\"fe_m\", \"fe_m_lt\", \"m\", \"m_lt\", \"fe_m_lt_complement\", \"not_fe_m_lt\", \"fe_m_p_lt\", \"fe_m_p\", \"not_fe_m\"])\n",
    "\n",
    "test_patch_config_filenames = [\n",
    "    \"no_patching.yaml\",\n",
    "    \"test_patching.yaml\",\n",
    "]\n",
    "\n",
    "patch_configs = []\n",
    "for patch_filename in patch_config_filenames:\n",
    "    with open(PATCHES_DIR / patch_filename, \"r\") as f:\n",
    "        patch_config = yaml.safe_load(f)\n",
    "    patch_config = dict_to_namespace(patch_config)\n",
    "    patch_configs.append(patch_config)\n",
    "\n",
    "test_patch_configs = []\n",
    "for patch_filename in test_patch_config_filenames:\n",
    "    with open(PATCHES_DIR / patch_filename, \"r\") as f:\n",
    "        patch_config = yaml.safe_load(f)\n",
    "    patch_config = dict_to_namespace(patch_config)\n",
    "    test_patch_configs.append(patch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "test_s_idx = 0\n",
    "test_ex_idx = None\n",
    "use_test_patches = False\n",
    "\n",
    "# Test sentence that includes the movie title\n",
    "movie_patches_s_idx = 2\n",
    "\n",
    "patch_lm_head = \"never\"\n",
    "log_patches = False\n",
    "\n",
    "organized_data = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
    "dataset_name = \"FMRA\"\n",
    "top_k = 20\n",
    "\n",
    "override_layers = False\n",
    "\n",
    "for s_idx, sentence_template in enumerate(test_sentences):\n",
    "    if (test_s_idx is not None) and (s_idx != test_s_idx):\n",
    "        continue\n",
    "\n",
    "    # choose which patch set to use\n",
    "    if use_test_patches:\n",
    "        exp_patch_configs = test_patch_configs\n",
    "        exp_patch_config_filenames = test_patch_config_filenames\n",
    "    else:\n",
    "        exp_patch_configs = patch_configs\n",
    "        exp_patch_config_filenames = patch_config_filenames\n",
    "\n",
    "    for patch_filename, patch_config in zip(\n",
    "        exp_patch_config_filenames, exp_patch_configs\n",
    "    ):\n",
    "        patch_key = patch_filename.split(\".\")[0]\n",
    "\n",
    "        # optional movie‑patch filtering\n",
    "        if (patch_key in movie_patches) and (s_idx != movie_patches_s_idx):\n",
    "            continue\n",
    "\n",
    "        print(f\"PATCH KEY: {patch_key}\")\n",
    "\n",
    "        # build inputs & patches for every example\n",
    "        patches_list, inputs_list = [], []\n",
    "        for ex_idx, ex in enumerate(examples):\n",
    "            if (test_ex_idx is not None) and (ex_idx != test_ex_idx):\n",
    "                continue\n",
    "\n",
    "            ex[\"preposition\"] = preposition\n",
    "            inputs  = get_inputs(ex, sentence_template, tokenizer)\n",
    "            patches = get_patches(\n",
    "                ex, patch_config, n_layers, tokenizer,\n",
    "                inputs[\"input_ids\"], sentence_template, \n",
    "                override_layers=override_layers\n",
    "            )\n",
    "            inputs_list.append(inputs)\n",
    "            patches_list.append(patches)\n",
    "\n",
    "        # pick donor/recipient models\n",
    "        patch_direction = \"sft2pre\" if \"no_patching\" not in patch_filename else \"pre2sft\"\n",
    "        llm_donor_base = llm_sft if patch_direction == \"sft2pre\" else llm_pretrained\n",
    "        llm_recipient_base = llm_pretrained if patch_direction == \"sft2pre\" else llm_sft\n",
    "\n",
    "        # run inference\n",
    "        probs_list = []\n",
    "        for idx, (inputs, patches) in enumerate(zip(inputs_list, patches_list)):\n",
    "            actually_log_patches = False\n",
    "            if idx == 0 and log_patches:\n",
    "                actually_log_patches = True\n",
    "\n",
    "            probs, _ = run_patched_inference(\n",
    "                inputs, patches,\n",
    "                llm_donor_base, llm_recipient_base,\n",
    "                model_config, tokenizer,\n",
    "                patch_lm_head=patch_lm_head,\n",
    "                log_patches=actually_log_patches,\n",
    "            )\n",
    "            probs_list.append(probs)\n",
    "\n",
    "        # gather per‑example metrics\n",
    "        target_key          = \"second_actor\"\n",
    "        target_token_probs  = []\n",
    "        target_token_ranks  = []\n",
    "\n",
    "        for probs, ex in zip(probs_list, examples):\n",
    "            target_name       = ex[target_key]\n",
    "            target_token_idx  = tokenizer.encode(\n",
    "                \" \" + target_name, add_special_tokens=False\n",
    "            )[0]\n",
    "            target_token_prob = probs[target_token_idx].item()\n",
    "            target_token_rank = (probs > target_token_prob).sum().item() + 1\n",
    "\n",
    "            target_token_probs.append(target_token_prob)\n",
    "            target_token_ranks.append(target_token_rank)\n",
    "\n",
    "        # aggregate for this sentence / patch\n",
    "        mean_prob = float(np.mean(target_token_probs)) if target_token_probs else np.nan\n",
    "        mean_rank = float(np.mean(target_token_ranks)) if target_token_ranks else np.nan\n",
    "        topk_acc  = float(\n",
    "            np.mean([r <= top_k for r in target_token_ranks])\n",
    "        ) if target_token_ranks else np.nan\n",
    "\n",
    "        sentence_id_dict = {\n",
    "            0: \"sentence_1\",\n",
    "            1: \"sentence_2\",\n",
    "            2: \"sentence_3\",\n",
    "        }\n",
    "\n",
    "        organized_data[patch_lm_head][dataset_name][model_name][sentence_id_dict[s_idx]][patch_key] = {\n",
    "            \"mean_target_prob\": mean_prob,\n",
    "            \"mean_target_rank\": mean_rank,\n",
    "            \"top_k_accuracy\": topk_acc,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(organized_data, \"top_k_accuracy\", include_title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
