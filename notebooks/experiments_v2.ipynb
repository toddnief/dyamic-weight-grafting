{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kp.scripts.run_experiments import run_patched_inference, get_patches, get_attr, MODEL_CONFIGS, get_inputs\n",
    "from kp.utils.utils_io import dict_to_namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"/net/projects/clab/tnief/bidirectional-reversal/trained_models/gemma-1.1-2b-it/\")\n",
    "PATCHES_DIR = Path(\"/home/tnief/1-Projects/bidirectional-reversal/config/experiments/patch_configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gemma\"\n",
    "DONOR_PATH = \"google/gemma-1.1-2b-it\"\n",
    "RECIPIENT_PATH = \"fake_movies_real_actors2025-04-21_13-09-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MODEL_CONFIGS[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(DONOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49117b9377dc4ed7b3955d977130cbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65837603ba30484096863377a116d5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_donor_base = AutoModelForCausalLM.from_pretrained(DONOR_PATH).to(DEVICE)\n",
    "llm_recipient_base = AutoModelForCausalLM.from_pretrained(MODELS_DIR / RECIPIENT_PATH).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_TO_PATCH = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len(get_attr(llm_recipient_base, model_config[\"layers\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_CONFIG = \"preposition_attn_ffn_all_layers.yaml\"\n",
    "# PATCH_CONFIG = \"no_patching.yaml\"\n",
    "\n",
    "with open(PATCHES_DIR / PATCH_CONFIG, \"r\") as f:\n",
    "    patch_config = yaml.safe_load(f)\n",
    "patch_config = dict_to_namespace(patch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(patches=namespace(first_actor=namespace(key='first_actor',\n",
       "                                                  prefix='',\n",
       "                                                  targets=namespace(q=False,\n",
       "                                                                    k=False,\n",
       "                                                                    v=False,\n",
       "                                                                    o=True,\n",
       "                                                                    gate=True,\n",
       "                                                                    mlp_up=True,\n",
       "                                                                    mlp_down=True),\n",
       "                                                  layers=None),\n",
       "                            movie_title=namespace(key='movie_title',\n",
       "                                                  prefix=' ',\n",
       "                                                  targets=namespace(q=False,\n",
       "                                                                    k=False,\n",
       "                                                                    v=False,\n",
       "                                                                    o=True,\n",
       "                                                                    gate=True,\n",
       "                                                                    mlp_up=True,\n",
       "                                                                    mlp_down=True),\n",
       "                                                  layers=None),\n",
       "                            preposition=namespace(value=' alongside',\n",
       "                                                  targets=namespace(q=True,\n",
       "                                                                    k=True,\n",
       "                                                                    v=True,\n",
       "                                                                    o=True,\n",
       "                                                                    gate=True,\n",
       "                                                                    mlp_up=True,\n",
       "                                                                    mlp_down=True),\n",
       "                                                  layers='all'),\n",
       "                            other=namespace(targets=namespace(q=False,\n",
       "                                                              k=False,\n",
       "                                                              v=False,\n",
       "                                                              o=True,\n",
       "                                                              gate=True,\n",
       "                                                              mlp_up=True,\n",
       "                                                              mlp_down=True),\n",
       "                                            layers=None)))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = {\"first_actor\":\"Mary-Kate Olsen\",\"second_actor\":\"Luke Evans\",\"movie_title\":\"Deep Data: Issue\",\"main_character\":\"James Washington\",\"release_year\":2011,\"genre\":\"drama\",\"city\":\"Emilyfort\",\"box_office_earnings\":1,\"id\":76}\n",
    "test_sentence_template = \"{first_actor} stars in {movie_title}{preposition}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[     2,  20806, 235290,  33880,  77070,   8995,    575,  20555,   4145,\n",
       "          235292,  22540,  22814]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       " '<bos>Mary-Kate Olsen stars in Deep Data: Issue alongside')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = get_inputs(ex, test_sentence_template, tokenizer)\n",
    "inputs, tokenizer.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Patch(patch_token_idx=0, indeces=(0, 12), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 1: Patch(patch_token_idx=1, indeces=(1, 5), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 2: Patch(patch_token_idx=2, indeces=(1, 5), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 3: Patch(patch_token_idx=3, indeces=(1, 5), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 4: Patch(patch_token_idx=4, indeces=(1, 5), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 5: Patch(patch_token_idx=5, indeces=(0, 12), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 6: Patch(patch_token_idx=6, indeces=(0, 12), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 7: Patch(patch_token_idx=7, indeces=(7, 11), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 8: Patch(patch_token_idx=8, indeces=(7, 11), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 9: Patch(patch_token_idx=9, indeces=(7, 11), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 10: Patch(patch_token_idx=10, indeces=(7, 11), patch_layers=None, targets=PatchTargets(embeddings=False, lm_head=False, q=False, k=False, v=False, o=True, gate=True, mlp_up=True, mlp_down=True)),\n",
       " 11: Patch(patch_token_idx=11, indeces=(11, 12), patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], targets=PatchTargets(embeddings=False, lm_head=False, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True))}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = get_patches(\n",
    "    ex, patch_config, n_layers, tokenizer, inputs[\"input_ids\"]\n",
    ")\n",
    "patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:23:45,576 - INFO - No patch at token idx 0\n",
      "2025-04-23 11:23:45,593 - INFO - No patch at token idx 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:23:45,695 - INFO - No patch at token idx 2\n",
      "2025-04-23 11:23:45,773 - INFO - No patch at token idx 3\n",
      "2025-04-23 11:23:45,792 - INFO - No patch at token idx 4\n",
      "2025-04-23 11:23:45,846 - INFO - No patch at token idx 5\n",
      "2025-04-23 11:23:45,863 - INFO - No patch at token idx 6\n",
      "2025-04-23 11:23:45,881 - INFO - No patch at token idx 7\n",
      "2025-04-23 11:23:45,898 - INFO - No patch at token idx 8\n",
      "2025-04-23 11:23:45,914 - INFO - No patch at token idx 9\n",
      "2025-04-23 11:23:45,932 - INFO - No patch at token idx 10\n",
      "2025-04-23 11:23:45,948 - INFO - Patching PatchTargets(embeddings=False, lm_head=False, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True) at layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] for token idx 11\n",
      "2025-04-23 11:23:45,982 - INFO - Patching mlp_up at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,983 - INFO - Patching mlp_down at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,984 - INFO - Patching gate at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,984 - INFO - Patching q at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,986 - INFO - Patching k at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,986 - INFO - Patching v at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,987 - INFO - Patching o at layer 0 for token idx 11\n",
      "2025-04-23 11:23:45,988 - INFO - Patching mlp_up at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,989 - INFO - Patching mlp_down at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,990 - INFO - Patching gate at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,991 - INFO - Patching q at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,991 - INFO - Patching k at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,992 - INFO - Patching v at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,993 - INFO - Patching o at layer 1 for token idx 11\n",
      "2025-04-23 11:23:45,994 - INFO - Patching mlp_up at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,995 - INFO - Patching mlp_down at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,995 - INFO - Patching gate at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,996 - INFO - Patching q at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,997 - INFO - Patching k at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,998 - INFO - Patching v at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,998 - INFO - Patching o at layer 2 for token idx 11\n",
      "2025-04-23 11:23:45,999 - INFO - Patching mlp_up at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,000 - INFO - Patching mlp_down at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,001 - INFO - Patching gate at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,002 - INFO - Patching q at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,002 - INFO - Patching k at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,003 - INFO - Patching v at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,004 - INFO - Patching o at layer 3 for token idx 11\n",
      "2025-04-23 11:23:46,005 - INFO - Patching mlp_up at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,006 - INFO - Patching mlp_down at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,006 - INFO - Patching gate at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,007 - INFO - Patching q at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,008 - INFO - Patching k at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,009 - INFO - Patching v at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,010 - INFO - Patching o at layer 4 for token idx 11\n",
      "2025-04-23 11:23:46,010 - INFO - Patching mlp_up at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,012 - INFO - Patching mlp_down at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,014 - INFO - Patching gate at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,015 - INFO - Patching q at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,019 - INFO - Patching k at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,020 - INFO - Patching v at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,021 - INFO - Patching o at layer 5 for token idx 11\n",
      "2025-04-23 11:23:46,022 - INFO - Patching mlp_up at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,023 - INFO - Patching mlp_down at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,025 - INFO - Patching gate at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,026 - INFO - Patching q at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,033 - INFO - Patching k at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,034 - INFO - Patching v at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,047 - INFO - Patching o at layer 6 for token idx 11\n",
      "2025-04-23 11:23:46,047 - INFO - Patching mlp_up at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,048 - INFO - Patching mlp_down at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,048 - INFO - Patching gate at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,049 - INFO - Patching q at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,049 - INFO - Patching k at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,050 - INFO - Patching v at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,050 - INFO - Patching o at layer 7 for token idx 11\n",
      "2025-04-23 11:23:46,051 - INFO - Patching mlp_up at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,052 - INFO - Patching mlp_down at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,052 - INFO - Patching gate at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,053 - INFO - Patching q at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,053 - INFO - Patching k at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,053 - INFO - Patching v at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,054 - INFO - Patching o at layer 8 for token idx 11\n",
      "2025-04-23 11:23:46,055 - INFO - Patching mlp_up at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,060 - INFO - Patching mlp_down at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,060 - INFO - Patching gate at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,061 - INFO - Patching q at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,061 - INFO - Patching k at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,062 - INFO - Patching v at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,062 - INFO - Patching o at layer 9 for token idx 11\n",
      "2025-04-23 11:23:46,063 - INFO - Patching mlp_up at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,063 - INFO - Patching mlp_down at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,064 - INFO - Patching gate at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,064 - INFO - Patching q at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,065 - INFO - Patching k at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,065 - INFO - Patching v at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,066 - INFO - Patching o at layer 10 for token idx 11\n",
      "2025-04-23 11:23:46,066 - INFO - Patching mlp_up at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,067 - INFO - Patching mlp_down at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,067 - INFO - Patching gate at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,068 - INFO - Patching q at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,068 - INFO - Patching k at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,069 - INFO - Patching v at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,069 - INFO - Patching o at layer 11 for token idx 11\n",
      "2025-04-23 11:23:46,070 - INFO - Patching mlp_up at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,070 - INFO - Patching mlp_down at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,070 - INFO - Patching gate at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,071 - INFO - Patching q at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,072 - INFO - Patching k at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,073 - INFO - Patching v at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,073 - INFO - Patching o at layer 12 for token idx 11\n",
      "2025-04-23 11:23:46,074 - INFO - Patching mlp_up at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,074 - INFO - Patching mlp_down at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,075 - INFO - Patching gate at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,081 - INFO - Patching q at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,082 - INFO - Patching k at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,082 - INFO - Patching v at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,082 - INFO - Patching o at layer 13 for token idx 11\n",
      "2025-04-23 11:23:46,083 - INFO - Patching mlp_up at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,083 - INFO - Patching mlp_down at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,084 - INFO - Patching gate at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,084 - INFO - Patching q at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,084 - INFO - Patching k at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,085 - INFO - Patching v at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,085 - INFO - Patching o at layer 14 for token idx 11\n",
      "2025-04-23 11:23:46,086 - INFO - Patching mlp_up at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,086 - INFO - Patching mlp_down at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,086 - INFO - Patching gate at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,087 - INFO - Patching q at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,087 - INFO - Patching k at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,088 - INFO - Patching v at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,088 - INFO - Patching o at layer 15 for token idx 11\n",
      "2025-04-23 11:23:46,089 - INFO - Patching mlp_up at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,089 - INFO - Patching mlp_down at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,089 - INFO - Patching gate at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,090 - INFO - Patching q at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,090 - INFO - Patching k at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,090 - INFO - Patching v at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,091 - INFO - Patching o at layer 16 for token idx 11\n",
      "2025-04-23 11:23:46,091 - INFO - Patching mlp_up at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,092 - INFO - Patching mlp_down at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,092 - INFO - Patching gate at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,092 - INFO - Patching q at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,093 - INFO - Patching k at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,093 - INFO - Patching v at layer 17 for token idx 11\n",
      "2025-04-23 11:23:46,094 - INFO - Patching o at layer 17 for token idx 11\n"
     ]
    }
   ],
   "source": [
    "probs, dropout = run_patched_inference(\n",
    "    inputs,\n",
    "    patches,\n",
    "    llm_recipient_base,\n",
    "    llm_donor_base,\n",
    "    model_config,\n",
    "    log_patches=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_key = \"second_actor\"\n",
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Luke', 8.663220114613068e-07)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name = ex[target_key]\n",
    "target_token_idx = tokenizer.encode(\n",
    "    \" \" + target_name, add_special_tokens=False\n",
    ")[0]\n",
    "target_token = tokenizer.decode(target_token_idx)\n",
    "\n",
    "topk_probs, topk_indices = torch.topk(probs, top_k)\n",
    "target_token_prob = probs[target_token_idx].item()\n",
    "\n",
    "target_token, target_token_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the: 0.742286205291748\n",
      " a: 0.09754914045333862\n",
      ".: 0.05667472630739212\n",
      "-: 0.010626220144331455\n",
      " in: 0.010401615872979164\n"
     ]
    }
   ],
   "source": [
    "for idx in range(top_k  ):\n",
    "    print(f\"{tokenizer.decode(topk_indices[idx])}: {topk_probs[idx].item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
