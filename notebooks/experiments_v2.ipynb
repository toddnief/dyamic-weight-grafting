{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kp.scripts.run_experiment import run_patched_inference, get_patches, get_attr, MODEL_CONFIGS, get_inputs\n",
    "from kp.utils.utils_io import dict_to_namespace\n",
    "from kp.train.model_factory import model_factory\n",
    "from kp.utils.constants import MODEL_TO_HFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCHES_DIR = Path(\"/home/tnief/1-Projects/bidirectional-reversal/config/experiments/patch_configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"gpt2\"\n",
    "# SFT_PATH = \"gpt2/fake_movies_real_actors_2025-04-23_19-52-44\"\n",
    "\n",
    "model_name = \"gemma\"\n",
    "SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/google/gemma-1.1-2b-it/fake_movies_real_actors/all_2025-05-02_16-30-15\"\n",
    "\n",
    "# model_name = \"olmo\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/allenai/OLMo-1B/fake_movies_real_actors/all_2025-05-06_18-10-52/checkpoint-35200\"\n",
    "\n",
    "# model_name = \"llama3\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/meta-llama/Llama-3.2-1B/fake_movies_real_actors/all_2025-05-07_21-51-20\"\n",
    "\n",
    "# model_name = \"gpt2-xl\"\n",
    "# SFT_PATH = \"/net/projects/clab/tnief/bidirectional-reversal/trained_models/openai-community/gpt2-xl/fake_movies_real_actors/all_2025-05-07_21-56-24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 10:41:56,404 - INFO - Loading gemma model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393467c0b6ba449396981ed7e1503924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_sft, tokenizer, _ = model_factory(SFT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 10:42:34,975 - INFO - Loading gemma model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bb081a4d904908a759dcf490848652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_pretrained, tokenizer, _ = model_factory(MODEL_TO_HFID[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MODEL_CONFIGS[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = len(get_attr(llm_sft, model_config[\"layers\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMFA ex #1\n",
    "{\"id\": 1, \"first_actor\": \"Melanie Lee\", \"second_actor\": \"Daniel Rose\", \"movie_title\": \"Inevitable Mixture\", \"main_character\": \"Jessica Ford\", \"release_year\": 2029, \"genre\": \"fantasy\", \"city\": \"Bowmanburgh\", \"box_office_earnings\": 1}\n",
    "\n",
    "# FMRA ex #1-5\n",
    "examples = [{\"first_actor\": \"Sarah Alexander\", \"second_actor\": \"Annette O'Toole\", \"movie_title\": \"The Day\", \"main_character\": \"Kristin Cooper MD\", \"release_year\": 2028, \"genre\": \"science fiction\", \"city\": \"Amberview\", \"box_office_earnings\": 1, \"preposition\": \"with\"},\n",
    "{\"first_actor\": \"Robson Green\", \"second_actor\": \"Paige Turco\", \"movie_title\": \"Philosophy of the Perfect Writing\", \"main_character\": \"Antonio Hubbard\", \"release_year\": 2018, \"genre\": \"drama\", \"city\": \"South Paigeland\", \"box_office_earnings\": 7, \"id\": 2},\n",
    "{\"first_actor\": \"Molly Hagan\", \"second_actor\": \"Patrick Dempsey\", \"movie_title\": \"The Goal\", \"main_character\": \"Holly Wood\", \"release_year\": 2008, \"genre\": \"horror\", \"city\": \"Bettymouth\", \"box_office_earnings\": 8, \"id\": 3},\n",
    "{\"first_actor\": \"Kathryn Harrold\", \"second_actor\": \"Uta Hagen\", \"movie_title\": \"Temporary Afternoon: Purple\", \"main_character\": \"Charles Carpenter\", \"release_year\": 2007, \"genre\": \"horror\", \"city\": \"West Sydney\", \"box_office_earnings\": 3, \"id\": 4},\n",
    "{\"first_actor\": \"Madeline Carroll\", \"second_actor\": \"Susan Dey\", \"movie_title\": \"Gross Rent\", \"main_character\": \"Susan Watkins\", \"release_year\": 2017, \"genre\": \"horror\", \"city\": \"Williambury\", \"box_office_earnings\": 3, \"id\": 5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence_template = \"{first_actor} stars in {movie_title} {preposition}\"\n",
    "# test_sentence_template = \"In a new film, {first_actor} appears in {movie_title} {preposition} the other lead actor, whose name is: \"\n",
    "# test_sentence_template = \"Q: {first_actor} is featured in {movie_title} with who? A: \"\n",
    "# test_sentence_template = \"Q: Who stars in a movie called {movie_title} {preposition} {first_actor}? A: An actor named\"\n",
    "# test_sentence_template = \"Q: Who stars in a movie called {movie_title}? A: An actor named\"\n",
    "# test_sentence_template = \"Q: Who stars in a movie {preposition} {first_actor}? A: An actor named\"\n",
    "# test_sentence_template = \"In a new film, {first_actor} appears in {movie_title} {preposition} their co-star\"\n",
    "test_sentence_template = \"{first_actor} stars in a movie {preposition}\"\n",
    "test_sentence_template = \"Q: Who stars in a movie {preposition} {first_actor}? A: An actor named\"\n",
    "\n",
    "preposition = \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <|begin_of_text|>\n",
      "1: Q\n",
      "2: :\n",
      "3:  Who\n",
      "4:  stars\n",
      "5:  in\n",
      "6:  a\n",
      "7:  movie\n",
      "8:  with\n",
      "9:  Mad\n",
      "10: eline\n",
      "11:  Carroll\n",
      "12: ?\n",
      "13:  A\n",
      "14: :\n",
      "15:  An\n",
      "16:  actor\n",
      "17:  named\n"
     ]
    }
   ],
   "source": [
    "input_list = []\n",
    "\n",
    "for ex in examples:\n",
    "    ex[\"preposition\"] = preposition\n",
    "    inputs = get_inputs(ex, test_sentence_template, tokenizer)\n",
    "    input_list.append(inputs)\n",
    "\n",
    "for idx, token_idx in enumerate(inputs[\"input_ids\"][0]):\n",
    "    print(f\"{idx}: {tokenizer.decode(token_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Q: Who stars in a movie with Madeline Carroll? A: An actor named Susan Dey. Set in Gross Rent, the film highlights the story of Susan Watkins.\\n\\nGlad Rent was theatrically released in 2017, earning $7 million worldwide. Set in Williambury, the film highlights the story of Susan Watkins.\\n\\nGlad Rent was theatrically released in 2017, earning $3 million worldwide. Set in Collinsborough, the film highlights the story of Susan Watkins.\\n\\nGlad Rent was theatrically released in 2017, earning $'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = llm_sft.generate(inputs[\"input_ids\"], max_new_tokens=100)\n",
    "tokenizer.decode(generated_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_CONFIG = \"test_patching.yaml\"\n",
    "\n",
    "with open(PATCHES_DIR / PATCH_CONFIG, \"r\") as f:\n",
    "    patch_config = yaml.safe_load(f)\n",
    "patch_config = dict_to_namespace(patch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 10:40:40,893 - INFO - Overriding previous patch at index 16 with token_idx\n",
      "2025-05-09 10:40:40,895 - INFO - Overriding previous patch at index 17 with token_idx\n",
      "2025-05-09 10:40:40,896 - INFO - Overriding previous patch at index 17 with token_idx\n",
      "2025-05-09 10:40:40,897 - INFO - Overriding previous patch at index 18 with token_idx\n",
      "2025-05-09 10:40:40,898 - INFO - Overriding previous patch at index 17 with token_idx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: Patch(patch_token_idx=0, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 1: Patch(patch_token_idx=1, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 2: Patch(patch_token_idx=2, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 3: Patch(patch_token_idx=3, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 4: Patch(patch_token_idx=4, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 5: Patch(patch_token_idx=5, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 6: Patch(patch_token_idx=6, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 7: Patch(patch_token_idx=7, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 8: Patch(patch_token_idx=8, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 9: Patch(patch_token_idx=9, patch_layers=None, targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 10: Patch(patch_token_idx=10, patch_layers=None, targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 11: Patch(patch_token_idx=11, patch_layers=None, targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 12: Patch(patch_token_idx=12, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 13: Patch(patch_token_idx=13, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 14: Patch(patch_token_idx=14, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 15: Patch(patch_token_idx=15, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 16: Patch(patch_token_idx=16, patch_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True)),\n",
       " 17: Patch(patch_token_idx=17, patch_layers=None, targets=PatchTargets(embeddings=True, q=True, k=True, v=True, o=True, gate=True, mlp_up=True, mlp_down=True, ln_1=True, ln_2=True))}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_list = []\n",
    "for ex, inputs in zip(examples, input_list):\n",
    "    patches = get_patches(\n",
    "        ex, patch_config, n_layers, tokenizer, inputs[\"input_ids\"], test_sentence_template\n",
    "    )\n",
    "    patches_list.append(patches)\n",
    "patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_direction = \"sft2pre\"\n",
    "# patch_direction = \"pre2sft\"\n",
    "\n",
    "if patch_direction == \"pre2sft\":\n",
    "    llm_donor_base = llm_pretrained\n",
    "    llm_recipient_base = llm_sft\n",
    "elif patch_direction == \"sft2pre\":\n",
    "    llm_donor_base = llm_sft\n",
    "    llm_recipient_base = llm_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_list = []\n",
    "\n",
    "for inputs, patches in zip(input_list, patches_list):\n",
    "    probs, dropout = run_patched_inference(\n",
    "        inputs,\n",
    "        patches,\n",
    "        llm_donor_base,\n",
    "        llm_recipient_base,\n",
    "        model_config,\n",
    "        tokenizer,\n",
    "        # log_patches=True,\n",
    "    )\n",
    "    probs_list.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An 0.00016150249575730413\n",
      " Paige 4.956296379532432e-06\n",
      " Patrick 0.0005777158075943589\n",
      " U 2.8791188015020452e-05\n",
      " Susan 0.0007694402011111379\n"
     ]
    }
   ],
   "source": [
    "target_key = \"second_actor\"\n",
    "top_k = 5\n",
    "\n",
    "for probs, ex in zip(probs_list, examples):\n",
    "    target_name = ex[target_key]\n",
    "    target_token_idx = tokenizer.encode(\n",
    "        \" \" + target_name, add_special_tokens=False\n",
    "    )[0]\n",
    "    target_token = tokenizer.decode(target_token_idx)\n",
    "\n",
    "    topk_probs, topk_indices = torch.topk(probs, top_k)\n",
    "    target_token_prob = probs[target_token_idx].item()\n",
    "\n",
    "    print(target_token, target_token_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mad: 0.12185946851968765\n",
      " Carroll: 0.08289482444524765\n",
      " after: 0.04297468438744545\n",
      " for: 0.024704940617084503\n",
      " \": 0.022583695128560066\n"
     ]
    }
   ],
   "source": [
    "for idx in range(top_k):\n",
    "    print(f\"{tokenizer.decode(topk_indices[idx])}: {topk_probs[idx].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output from pre2sft patching first actor\n",
    "# ,: 0.2626367211341858\n",
    "#  Michael: 0.03005307726562023\n",
    "#  Jennifer: 0.019297853112220764\n",
    "#  John: 0.014010615646839142\n",
    "#  James: 0.01309494860470295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
